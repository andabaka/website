---
title: "Analiza potrošačke košarice"
author: "Marijana Andabaka"
date: "21.03.2023."
output: 
  rmdformats::material:
    cards: false
    highlight: tango
    use_bookdown: true
    df_print: tibble
    css: css/styles.css
    lightbox: true
    code_folding: hide
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
    eval       = TRUE,
    warning    = FALSE,
    message    = FALSE
    )
```

![Slika preuzeta sa Pexels
(https://www.pexels.com/photo/appetizer-bake-baked-baking-372851/)](img/img1.jpg)

# UVOD  {.tabset .tabset-pills}

Analiza potrošačke kosarice (engl. *Market Basket Analysis*, *Affinity Analysis*) je proces razumijevanja odnosa između kupaca i proizvoda/usluga koje kupuju odnosno njihovih potrošačkih navika. Cilj je pronaći artikle koji se pojavljuju zajedno u transakcijama što omogućuje primjenu ciljnih strategija poput raspodjele artikala unutar trgovina, davanje popusta na artikle koji se često prodaju zajedno te kreiranja preporuka proizvoda s ciljem privlačenja kupaca i navođenja na neplaniranu potrošnju. Postoji nekoliko metoda analize potrošačke košarice:

- __Kolaborativno filtriranje__ (engl. *Collaborative Filtering*)
- __Pravila pridruživanja__ (engl. *Association Rules*)
- __Popularni artikli__ (engl. *Item Popularity*)
- __Kontekstno bazirani sustavi za preporuke__ (engl. *Content-Based-Filtering*)
- __Hibridni modeli__

__Pritisnite donje kartice__ kako biste saznali nešto više o metodama koje će se  koristiti u ovom projektu. 

## Kolaborativno filtriranje

__Kolaborativno filtriranje__ temelji se na sličnostima korisnika ili proizvoda koje se računaju putem unaprijed definirane funkcije sličnosti (engl. *similarity function*). Funkcija sličnosti numerički određuje udaljenost (npr. euklidska udaljenost, Pearson korelacija, kosinus udaljenost) između dva korisnika ili proizvoda u svrhu definiranja onih koji su najbliži.

Sustavi orijentirani prema korisniku (engl. *user-based collaborative filtering*) pronalaze slične korisnike za određenog promatranog korisnika te se temelje na pretpostavci da slični korisnici preferiraju slične proizvode. 

Sustavi orijentirani prema proizvodima (engl. *item-based collaborative filtering*) pronalaze slične proizvode za određeni promatrani proizvod te se temelje na pretpostavci da slične proizvode preferiraju slični korisnici.

## Pravila pridruživanja

Metoda __pravila pridruživanja__ jedna je od najčešće korištenih metoda u analiziranju potrošačke košarice ili transakcijskih podataka. Cilj je otkriti specifične uzorke ili pravila unutar skupa promatranih podataka na temelju koncepta strogih pravila. Pravila između dva kupljena proizvoda nastaju pomoću tri veličine: 

- značaj (engl. *support*) je vjerojatnost da se dvije stavke istovremeno pojavljuju $${P(stavka1,stavka2)}$$
- pouzdanost (engl. *confidence*) predstavlja značaj podijeljen sa vjerojatnošću kupnje druge stavke $$\frac{znacaj}{P(stavka2)}$$
- poboljšanje (engl. *lift*) je pouzdanost podijeljenja sa vjerojatnošću kupnje prve stavke $$\frac{pouzdanost}{P(stavka1)}$$

Kad se ove veličine kombiniraju, stavke sa najvećom vjerojatnošću kupnje su one koje imaju najveće poboljšanje. Metoda se odlikuje brzinom i dobrim funkcioniranjem kod analize predmeta koji se najčešće kupuju. 

## Popularni artikli

Strategija primjene metode __popularni artikli__ je vrlo jednostavna. Artikli se razvrstavaju na temelju učestalosti kupnje (tj. popularnosti) u svrhu razumijevanja kupovnih navika. Sustav preporuka se temelji samo na najčešće kupljenim artiklima koji se trenutno ne kupuju. Loše strana ovog pristupa je njegova jednostavnost i nedostatak nekih temeljnih sličnosti unutar segmenata ili skupina kupaca. 

# ANALIZA

U ovom projektu napravit cemo nekoliko modela putem metoda kolaborativnog filtriranja, pravila pridruzivanja i popularnosti unutar `recommenderlab` paketa.
 `recommenderlab` paket omogucuje procjenu i usporedbu razlicitih algoritama te brzo uspostavljanje za odabir najboljeg modela.

## Ucitavanje paketa

Za provedbu analize ucitani su potrebn paketi: `recommenderlab`, `tidyverse`, `tidyquant`, `fs`, `knitr`, `glue`, `cowplot`

```{r}
library(recommenderlab) # izrada algoritama preporuka
library(tidyverse) # priprema podataka
library(tidyquant) # tema za grafove
library(fs)
library(knitr)
library(glue)
library(DT) # interaktivne tablice
```

## Baza podataka

Podaci pripadaju pekarnici The Bread Basket koja se nalazi u Edinburghu te sadrzi transakcije kupaca koji su online narucili razlicite artikle u vremenskom rzdoblju od 26.1.2011. do 27.12.2013. Baza ima 20.507 unosa preko 90.000 transakcija i 5 obiljezja (stupca).

Obiljezja: 

- __TransactionNo__: jedinstveni broj transakcije
- __Items__: kupljene stavke
- __DateTime__: datum i vrijeme transakcije
- __Daypart__: dio dana kad je transakcija obavljena (jutro, popodne, vecer, noc)
- __DayType__: da li je transakcija izvrsena vikendom ili radnim danima

```{r}
# Unos baze podataka
data_bakery <- read.csv("Data/Bakery.csv")
datatable(data_bakery)

```


## CRISP-DM metodologija 

Za provedbu projekta primijenjena je metodologija [CRoss Industry Standard Process for Data Mining (CRISP-DM)](https://en.wikipedia.org/wiki/Cross-industry_standard_process_for_data_mining.). Kroz CRISP-DM model podaci se dubinski analiziraju kao iterativan proces koji se sastoji od 6 faza (Slika 2).    

```{r, out.width="50%", fig.align="center", fig.cap= "Slika 2. CRISP-DM standard"}
include_graphics("img/crisp-dm.png")
```

### Razumijevanje problema (Bussines Understanding)

Problem koji se zeli rijesiti je taj da organizacija potencijalno moze ostvariti vecu zaradu na nacin da preporucuje odredene proizvode odredenim kupcima. Kupci cesto odlaze u trgovinu ili posjecuju web stranice iz odredenih razloga sto predstavlja glavnu priliku za povecanje prodaje preporukom proizvoda o kojima kupac mozda ne razmislja. To mogu biti slicni proizvodi koje su kupci kupili ili proizvodi koji su kupljeni sa slicnim artiklima.

### Razumijevanje podataka (Data Understanding)

Prvo cemo pogledati koliko se cesto pojedini artikli kupuju te odrediti popularne artikle.

```{r}
# Pogled na podatke
data_bakery %>% glimpse()

# Formatiranje varijable datum i vrijeme
data_bakery_tbl <- data_bakery %>% 
  mutate(Date = as.Date(DateTime),
         Time = format(as.POSIXct(DateTime), format = "%H:%M:%S"),
         DayType = as.factor(DayType),
         Daypart = as.factor(Daypart))
  
# Nedostajuce vrijednosti
data_bakery_tbl %>%  summarise_all(~sum(is.na(.)))

options(scipen=999)

# Frekvencije prodanih artikala
data_bakery_freq <- data_bakery_tbl %>% 
  count(Items) %>% 
  arrange(desc(n)) %>% 
  mutate(pct = n/sum(n),
         cum_pct = cumsum(pct)) 
  
```
Nakon pogleda na bazu utvrdili smo da ne postoje nedostajuce vrijednosti, varijablu DaTime smo stavili u odgovarajuci format te odvojili datum od vrmenea u dva zasebna obiljezja. Najprodavaniji artikl je kava sa 27% od ukupnog broja prodanih proizvoda. Uz kavu, kruh i caj cine 50% ukupne porodaje. U grfu cemo vizualizirati top 10 artikala.

```{r}
# 10 najpopularnijih artikala
data_bakery_freq %>% 
  top_n(10, wt = n) %>% 
  ggplot(aes(x = reorder(Items,n), y = n)) +
  geom_bar(stat = "identity", fill = "#2C3E50") +
  labs(title = "10 najpopularnijih artikala", x= "", y = "Broj prodanih artikala")+
  theme_tq() +
  scale_color_tq() +
  coord_flip() +
  scale_y_continuous(n.breaks = 6)
```
Na grafu mozemo vidjeti da se u top 10 najprodavanijih artikala nalaze kava, kruh, caj, kolac, pecivo, sendvic, medialunas (argentinsko pecivo), vruca cokolada, keksi i brownie.

```{r}
data_bakery_tbl %>% 
  ggplot(aes(Daypart)) +
  geom_histogram(stat = "count", fill = "#2C3E50") +
  theme_tq() +
  labs(title = "Frekvencija narudzbi s obzirom na dio dana",
        y = "",
        x = "Dio dana")
```

```{r}
data_bakery_tbl %>% 
  ggplot(aes(wday(Date,
                  week_start = getOption("lubridate.week.start", 1)))) +
  geom_histogram(stat = "count", fill = "#2C3E50") +
  scale_x_continuous(breaks = c(1,2,3,4,5,6,7),
                     labels = c("Pon", "Uto", "Sri", "Cet", "Pet", "Sub", "Ned")) + theme_tq() +
  labs(title = "Narudbe prema danima u tjednu",
       y = "",
       x = "")
```

```{r}
data_bakery_tbl %>% 
  ggplot(aes(hour(hms(Time)))) +
  geom_histogram(stat = "count", fill = "#2C3E50") +
  theme_tq() +
  labs(title = "Narudbe prema satima u danu",
       y = "",
       x = "Sati u danu")
  
```
Najveci broj narudzbi ostvaruje se poslijepodne i ujutro vikendima, najvise subotom izmedu 10.00 i 14.00 sati

## Priprema podataka 

Podatke cemo formatirati u 2x2 matricu sa redovima kao narudzbama i stupcima kao proizvodima. Ovaj format se cesto naziva *user-item* matrica zato jer se korisnici (npr. kupci ili narudzbe) nalaze u redovima a stavke (npr. proizvodi) u stupcima.
Sljedeci korak je da uzorak pretvorimo u format *matrice ocjena* koju koristi `recommenderlab`paket. Ovaj tip matrice potreban je za analizu te iz tog razloga normalizacija podataka nije potrebna je binarna matrica ocjena koja se sastoji od 0 i 1 oznacavajuci da li je ili nije proizvod kupljen. Iz tog razlog normalizacija podataka nije potrebna.

Prije kreiranja matrice, provjerit cemo da li narudzbe sadrze isti artikli vise nego jednom.

```{r}
# Filtriranje po broju narudzbe i artiklu
data_bakery_tbl %>% 
  filter(TransactionNo == 2 & Items == "Scandinavian") %>% 
  select(TransactionNo, Items)
  
```
Mozemo vidjeti da pojedine narudzbe sadrze iste artikle vise puta te cemo obrisati duplikate jer nas zanima samo da li je pojedini artikl narucen ili nije. 

```{r}
# Kreiranje jedinstvenog identifikatora istih artikala na istoj narudbi
data_bakery_tbl <- data_bakery_tbl %>% 
# Brisanje duplikata i identifikatora  
  mutate(TranNo_Item = paste(TransactionNo, Items, sep = ' ')) %>% 
  distinct(TranNo_Item, .keep_all = TRUE) %>% 
  select(-TranNo_Item)

data_bakery_tbl
```

Sads mozemo pristupiti izradi *user-item* matrice za koju cemo odabrati potrebne varijable (broj narudzbe i artikle).

```{r}
ratings_matrix <- data_bakery_tbl %>% 
  select(TransactionNo, Items) %>% 
  mutate(value = 1) %>% 
  spread(Items, value, fill = 0) %>% 
  select(-TransactionNo) %>% 
  as.matrix() %>% 
  as("binaryRatingMatrix")

```

### Modeliranje (Data Modeling)

#### Trening/test podjela
`recommenderlab` paket omogucava procjenu i usporedbu razlicitih algoritama te brzo odredivanje najprikladnijeg pristupa. Kako bi se uspostavila ucinkovitost modela podatke cemo podijeliti u skupove za treniranje i testiranje postavljanjem train = 0.8 za 80/20 treniranje/testiranje. Takoder možemo postaviti 5-fold kros validaciju sa k=5, medutim  kako bi smo smanjili vrijeme obrade odabrat cemo k = NULL. Takoder smo postavili method = "cross" i k = 5 za 5-fold kros-validaciju. Ovo znaci da su podaci podijeljeni u k podskupve jednake velicine pri cemu se 80% podataka korisiti za treniranje a preostalih 20% za testiranje. Modeli se rekurzivno procjenjuju 10 puta svaki put koristeci razlicitu trening/test podjelu sto osigurava da se svi proizvodi uzimjau u obzir iz trening i za testiranje. Zatim se moze izracunati prosjek rezultata kako bi se proizveo jedan skup za procjenu. Zadana postavka given = -1 znaci da ce se sve stavke osim jedne koristiti za ucenje a preostala stavka ce se koristiti za evaluaciju.

```{r}
eval_scheme <- ratings_matrix %>% 
  evaluationScheme(method = "cross",
                   train  = 0.8,
                   k      = 5,
                   given  = -1)
eval_scheme
```

#### Algoritmi

```{r}
list_algorithms <- list(
  "random items"      = list(name = "RANDOM",
                        param = NULL),
  "popular items"     = list(name = "POPULAR",
                        param = NULL),
  "user-based CF"     = list(name = "UBCF",
                        param = list(method = "Cosine", nn = 500)),
  "item-based CF"     = list(name = "IBCF",
                        param = list(k = 5)),
  "association rules" = list(name = "AR",
                        param = list(supp = 0.01, conf = 0.01))
)
```

#### Procjena algoritama

Algoritme cemo analizirati pomocu funkcije evaluate() specificirajuci type = "topNList" za procjenu Top N Liste preporuka proizvoda i n = 1:10 za procjenu tocnosti od 1 do 10  preporuka.

```{r}
results <- recommenderlab::evaluate(
  eval_scheme,
  list_algorithms,
  type  = "topNList",
  n     = 1:10)

results
```

#### Procjena modela
 
Rezultat je lista koja sadrzi 5 evaluacija. Svaki model se moze istraziti pomocu `getConfusionMatrix()`funkcije koja prikazuje listu sa matricom. U nastavku je prikazan primjer za "random items" model.

```{r}
cf_matrix_model <-results$`random items` %>% 
  getConfusionMatrix() %>% 
  as.list()

# Izracun prosjecene vrijednosti 5-fold kros validacije i odabir potrebnih stupaca
as.data.frame(Reduce("+", cf_matrix_model) / length(cf_matrix_model)) %>% 
  select("n", "precision", "recall", "TPR", "FPR")
  

 
```
Prethodne korake pretvorit cemo u funkciju i primijenit ju na sve elemente u listi. Zatim korisitimo funkciju `map()` kako bismo sve rezultate imali urednom formatu te `enframe()` i 
`unnest()` za dobivanje rezultata u jednoj razini kako bismo mogli usporediti modele.

```{r}
# Funkcija
avg_confusion_matrix <- function(results) {
    cf_matrix_model <- results %>%
        getConfusionMatrix() %>%
         as.list()
as.data.frame(Reduce("+", cf_matrix_model) / length(cf_matrix_model)) %>% 
  select("n", "precision", "recall", "TPR", "FPR")
}


# Iteracija fukcije kroz sve modele
results_tbl <- results %>% 
  map(avg_confusion_matrix) %>% 
  enframe() %>% 
  unnest()

results_tbl
```

#### Vizualizacija performansi modela

Performanse modela cemo usporediti pomocu krivulje operativne karakteristike prijemnika ili ROC krivulje. Klasifikacijski modeli se obicno usporeduju sa ROC (engl. *Receiver operating characteristic*) grafom koji prikazuje stvarno pozitivnu stopu (engl. *true positive rate*, TPR) u odnosu na lazno pozitivnu stopu (engl. *false positive rate*, FPR). TPR je smjesten na osi y, FPR na osi x a sto je veca povrsina ispod ROC krivulje model pokazuje bolje performanse u odnosu na ostale. Pomocu funkcije `fct_reorder2()` poslozit cemo modele po najboljim FPR i TPR vrijednostima.  

```{r}
results_tbl %>% 
  ggplot(aes(FPR, TPR,
             colour = fct_reorder2(as.factor(name), FPR, TPR))) +
  geom_line() +
  geom_label(aes(label = n)) +
  theme_tq() +
  scale_color_tq() + 
  theme(legend.position = "right",
        legend.direction = "vertical") +
  labs(title = "ROC krivulja",
       subtitle = "Najbolji model: Popular Items (Popularne stavke)",
       color = "Model Type")
 
  

```
Model *item-based CF* pokazao se kao najbolji jer postize najvisi TPR za bilo koju razinu FPR-a, odnosno model proizvodi najveci broj relevantnih preporuka (*true positives*) za istu razinu nerelevantnih preporuka (*false positives*). 

Performanse modela mozemo usporediti i sa PR (odnos odziva i preciznosti) krivuljom (engl. *Precision-Recall curve*). Preciznost pokazuje koliko su modeli osjetljivi na lazno pozitivne (tj. preporuka artikala za koje nije vjerojatno da ce biti kupljeni) dok odziv (drugi naziv za TPR) pokazuje koliko su modeli osjetljivi na lazno negativne (tj. model ne predlaze stavku za koju potoji velika vjerojatnost da ce biti kupljena). U konacnici cilj je tocno predvidanje artikala koji ce vrlo vjerojatno biti kupljeni jer bi to imalo pozitivan utjecaj na prodaju i prihode. Odnosno, zelimo povecati odziv (ili smanjiti lazno negativne) za istu razinu preciznosti.

```{r}
results_tbl %>% 
  ggplot(aes(recall, precision,
             color = fct_reorder2(as.factor(name), recall, precision))) +
  geom_line() +
  geom_label(aes(label = n)) +
  theme_tq() +
  scale_color_tq() +
  theme(legend.position = "right",
        legend.direction = "vertical") +
  labs( title = "Preciznost i Odziv (Precision Vs Recall",
        color = "Model Type")
```

Graf preciznosti i odziva potvrduje da je *item-based CF* najbolji model sto znaci da minimizira lazno negativne (tj. ne predlaze stavku za koju je vrlo vjerojatno da ce se kupiti) za sve razine lazno negativnih preporuka.

### Generiranje predikcija 

Nakon sto smo saznali koji model ima najbolje performanse, mozemo pristupiti testiranju predikcija. Da bismo to ucinili, stvoriti cemo hipotetsku novu narudzbu koja sadrzi dzem, mineralnu vodu i kruh (engl. *Jam*, *Mineral Water*, *Bread*) te ju staviti u odgovarajuci format koji recomenderlab koristi i na kraju nasu izmisljenu narudbu proslijedujemo u funkciju za predvidanje. 

```{r}
# Stvaranje recommender-a sa postavkama najboljeg modela
train_recLab <- getData(eval_scheme, "train")

fit_PopularItm<- recommenderlab::Recommender(
  train_recLab,
  method = "POPULAR",
  param = NULL)

fit_PopularItm

# Stvaranje hipotetske narudzbe
new_order <- c("Jam", "Mineral Water", "Bread")


```
Prije nego sto napravimo predikciju, narudbu cemo pretvoriti u format koji recommnedrlab zahtjeva a to je matrica ocjena (podaci sirokog formata) s nazivima stupaca koji odgovaraju trening setu podataka te jedinice i nule za prisutnost stavke u narudzbi.

```{r}
# Izvlacenje naziva stupaca iz trening seta podataka
items_names <- train_recLab@data %>% colnames()

# Stvaranje matrice nove narudzbe
new_order_matrix <- tibble(
  item = items_names) %>% 
  mutate(value = as.numeric(item %in%new_order)) %>% 
  spread(key = item, value = value) %>% 
  as.matrix() %>% 
  as("binaryRatingMatrix")

```

Sada mozemo koristit predict() funkciju u koju unosimo Recommender, novu narudzbu i broj predvidanja koja zelimo napraviti. Odabrat cemo 5 predikcija za 5 njapoularnijh artikala koje su slicni kupci kupili.

```{r}
prediction <- predict(fit_PopularItm, 
                newdata = new_order_matrix, 
                n       = 5)
```

```{r}
extract_predictions <- function(predictions, user) {
    predictions@itemLabels[predictions@items[[user]]]
}

prediction %>% 
  extract_predictions(1)
```